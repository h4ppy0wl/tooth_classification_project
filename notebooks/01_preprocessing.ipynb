{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create master json files from the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(parent_dir)\n",
    "import src.data_pipeline as dp\n",
    "from src.config import Config\n",
    "from src.model import create_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. create the config file\n",
    "2. filter the raw dataset and create a filtered dataset json in the interim folder\n",
    "3. split and create the train, val, and test jsons from interim folder\n",
    "4. parse target ds json\n",
    "5. create train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_config = Config()\n",
    "my_config.INITIAL_LR = 0.01\n",
    "raw_json_path = \"C:/Users/anedaeij23/Project/tooth_classification_project/data/raw/complete_toothwise_annotations.json\"\n",
    "intrim_dir = \"C:/Users/anedaeij23/Project/tooth_classification_project/data/intrim\"\n",
    "img_dir = \"C:/Users/anedaeij23/Project/tooth_classification_project/data/raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering out dark images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "removing dark images: 100%|██████████| 865/865 [00:38<00:00, 22.40oral cavity image/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filtered annotations: 865\n",
      "Converting annotations...\n",
      "Number of annotations: 10017\n",
      "Saving filtered annotations...\n",
      "Done pre-processing the dataset.\n"
     ]
    }
   ],
   "source": [
    "dp.preprocess_raw_dataset(raw_json_path, intrim_dir, my_config , verbose= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_json_path = os.path.join(intrim_dir, \"filtered_Pla_annotations.json\")\n",
    "\n",
    "dp.split_dataset_json(master_json_path, intrim_dir, my_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_json_path = os.path.join(intrim_dir, \"Pla_filtered_train.json\")\n",
    "train_records = dp.parse_dataset_json(ds_json_path, my_config, is_train_ds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dp.build_tf_dataset(train_records, my_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_json_path = os.path.join(intrim_dir, \"Pla_filtered_val.json\")\n",
    "val_records = dp.parse_dataset_json(ds_json_path, my_config, is_train_ds=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = dp.build_tf_dataset(val_records, my_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume ds is your built tf.data.Dataset\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(\"Images batch shape:\", images.shape)\n",
    "    print(\"Images dtype:\", images.dtype)\n",
    "    print(\"Labels batch shape:\", labels.shape)\n",
    "    print(\"Labels dtype:\", labels.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Iterate over one batch from your dataset\n",
    "for images, labels in train_ds.take(1):\n",
    "    images_np = images.numpy()   # Convert the tensor to a NumPy array.\n",
    "    labels_np = labels.numpy()   # Likewise for labels.\n",
    "    \n",
    "    # Display each image in the batch.\n",
    "    for i in range(images_np.shape[0]):\n",
    "        # Depending on how your images are preprocessed, you may need to clip or cast them.\n",
    "        # For example, if they are float values in the range [0, 255], you can cast to uint8:\n",
    "        image_to_show = np.clip(images_np[i], 0, 255).astype(np.uint8)\n",
    "        \n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.imshow(image_to_show)\n",
    "        plt.title(f\"Label: {labels_np[i]}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 256, 256, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG batch shapes: [TensorShape([32, 256, 256, 3]), TensorShape([32])]\n"
     ]
    }
   ],
   "source": [
    "for batch in train_ds.take(1):\n",
    "    print(\"DEBUG batch shapes:\", [x.shape for x in batch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = create_model(my_config, 'transfer', trainable_base = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " preprocessing_layer (Lambd  (None, 256, 256, 3)       0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 8, 8, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2048)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 2048)              8192      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " classification_output (Den  (None, 1)                 257       \n",
      " se)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24120705 (92.01 MB)\n",
      "Trainable params: 528897 (2.02 MB)\n",
      "Non-trainable params: 23591808 (90.00 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import train_transfer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting initial training...\n",
      "Epoch 1/2\n",
      "319/319 [==============================] - 947s 3s/step - loss: 1.9381 - accuracy: 0.7507 - precision: 0.6231 - recall: 0.5596 - auc: 0.7537 - val_loss: 0.7117 - val_accuracy: 0.8473 - val_precision: 0.2927 - val_recall: 0.0882 - val_auc: 0.6920\n",
      "Epoch 2/2\n",
      "319/319 [==============================] - 922s 3s/step - loss: 0.7405 - accuracy: 0.7958 - precision: 0.7236 - recall: 0.5860 - auc: 0.8271 - val_loss: 0.6478 - val_accuracy: 0.8483 - val_precision: 0.3182 - val_recall: 0.1029 - val_auc: 0.6979\n",
      "Initial model weights saved to: initial_weights.h5\n",
      "Fine-tuning model...\n",
      "Epoch 1/2\n",
      "319/319 [==============================] - 938s 3s/step - loss: 0.6950 - accuracy: 0.8181 - precision: 0.8372 - recall: 0.5360 - auc: 0.8454 - val_loss: 0.6478 - val_accuracy: 0.8483 - val_precision: 0.3182 - val_recall: 0.1029 - val_auc: 0.6979\n",
      "Epoch 2/2\n",
      "319/319 [==============================] - 922s 3s/step - loss: 0.6931 - accuracy: 0.8204 - precision: 0.8419 - recall: 0.5403 - auc: 0.8454 - val_loss: 0.6478 - val_accuracy: 0.8483 - val_precision: 0.3182 - val_recall: 0.1029 - val_auc: 0.6979\n"
     ]
    }
   ],
   "source": [
    "h1, h2 = train_transfer_model(my_model, train_ds, val_ds, my_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "path = 'C:/Users/anedaeij23/Project/tooth_classification_project/data/raw/MOVIPKA-front_right-right-120_PumM5JqRU3.jpg'\n",
    "dark_result = dp.is_darker_than_threshold(path, 0.25)\n",
    "print(dark_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tooth_diag_annots = json.load(open(os.path.join(\"C:/Users/anedaeij23/Project/tooth_classification_project/data/raw/\", \"complete_toothwise_annotations.json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_json = dp.remove_dark_images_from_json(tooth_diag_annots, \"C:/Users/anedaeij23/Project/tooth_classification_project/data/raw/\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "plaque_annotations = dp.convert_annotations(tooth_diag_annots, target_class='Pla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new annotations to a file\n",
    "with open(\"C:/Users/anedaeij23/Project/tooth_classification_project/data/intrim/plaque_annotations.json\", \"w\") as f:\n",
    "    json.dump(plaque_annotations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'C:/Users/anedaeij23/Project/tooth_classification_project/data/raw/HAJEVSU-front_left-left-315_nq0WmtTmrN.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "image = io.imread(img_path)\n",
    "# image = tf.io.read_file(img_path)\n",
    "# image = tf.image.decode_jpeg(image, channels=3)\n",
    "img = dp.pad_and_resize(image)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering out dark images...\n",
      "JUKUJKA-front_left-left-363_79Ils3voSf.jpg was dark, removed\n",
      "HIKOJSI-front_right-right-105_eaY2aW5hSH.jpg was dark, removed\n",
      "TUREVTA-front_left-left-311_FlNiW2pc9R.jpg was dark, removed\n",
      "TUREVTA-front_left-left-311_aPuvqDg1Fa.jpg was dark, removed\n",
      "KINOPTA-front_right-right-297_QvKzBksRPQ.jpg was dark, removed\n",
      "HUNIHTU-front_left-left-478_NI7y31wkUU.jpg was dark, removed\n",
      "HUNIHTU-front_left-left-478_YjaKKtiF7W.jpg was dark, removed\n",
      "PETIHPO-front_left-left-253_tf6WFxiCa1.jpg was dark, removed\n",
      "PETIHPO-front_left-left-253_xw8zLfdv6Q.jpg was dark, removed\n",
      "HAJATRO-front-392_P9pRrEUCqs.jpg was dark, removed\n",
      "HAJATRO-front-392_lTj0bz6PtH.jpg was dark, removed\n",
      "HAJATRO-front-392_SKoRG6M0Mc.jpg was dark, removed\n",
      "HAJATRO-front-392_cgHPkHdoyI.jpg was dark, removed\n",
      "HAJATRO-front-392_ncb6GWaFqV.jpg was dark, removed\n",
      "HAJATRO-front-392_UgoxN-H4hh.jpg was dark, removed\n",
      "KIJOLLA-upper-116_871HM4EYSa.jpg was dark, removed\n",
      "KIJOLLA-upper-116_1OhrWOmK3N.jpg was dark, removed\n",
      "KIJOLLA-upper-116_cmmMy-mos_.jpg was dark, removed\n",
      "LEKEMKA-upper-402_QBYdYFWzWe.jpg was dark, removed\n",
      "VULAPJO-front_left-left-394_S2D1ZrvYue.jpg was dark, removed\n",
      "VULAPJO-front_left-left-394_75SgkCSLyH.jpg was dark, removed\n",
      "VULAPJO-front_left-left-394_iNH7fR0RlM.jpg was dark, removed\n",
      "VULAPJO-front_right-right-394_llBTrkxHqk.jpg was dark, removed\n",
      "VULAPJO-front_right-right-394_LfwhcmsuqX.jpg was dark, removed\n",
      "VULAPJO-front_right-right-394_KtuYnoFN_N.jpg was dark, removed\n",
      "VULAPJO-front_right-right-394_tlJvN15v8G.jpg was dark, removed\n",
      "VULAPJO-front_right-right-394_xZc9tFQUx0.jpg was dark, removed\n",
      "VULAPJO-front_right-right-394_19pNj-SPbl.jpg was dark, removed\n",
      "VULAPJO-lower-394_GOjvEkHX8F.jpg was dark, removed\n",
      "VULAPJO-lower-394_kg6WLOE_-b.jpg was dark, removed\n",
      "VULAPJO-lower-394_UsP6bkeb6-.jpg was dark, removed\n",
      "VULAPJO-lower-394_dSp43v3JR9.jpg was dark, removed\n",
      "LOKESNI-upper-176_S6C_X3zy5X.jpg was dark, removed\n",
      "LOKESNI-upper-176_G3QUwYQvc8.jpg was dark, removed\n",
      "SUTUNJO-front_left-left-141_aLaSBmYLl2.jpg was dark, removed\n",
      "SUTUNJO-front_left-left-141_JuLpoIuKNM.jpg was dark, removed\n",
      "SUTUNJO-upper-141_z3sGZd4m9m.jpg was dark, removed\n",
      "NAVAHJA-front_left-left-464_ckIza7EtJG.jpg was dark, removed\n",
      "NAVAHJA-front_right-right-464_DN_UZcvi1C.jpg was dark, removed\n",
      "POHAMSE-front_left-right-12_iXRHirmI40.jpg was dark, removed\n",
      "REVUKPI-front_right-right-133_Un8C8-nYuh.jpg was dark, removed\n",
      "REVUKPI-front_right-right-133_RGj3XL87Fd.jpg was dark, removed\n",
      "VOLIPHA-front_left-left-452_e6SKtaSl1u.jpg was dark, removed\n",
      "VOLIPHA-front_left-left-452_VRIAJyssG_.jpg was dark, removed\n",
      "VOLIPHA-front_left-left-452_aAOx0G6eUP.jpg was dark, removed\n",
      "VOLIPHA-front_left-left-452_tP5kIn-5c7.jpg was dark, removed\n",
      "VOLIPHA-front_right-right-452_km_-jgRzCX.jpg was dark, removed\n",
      "VOLIPHA-front-452_qB5MxNbZtJ.jpg was dark, removed\n",
      "VOLIPHA-front-452_fAbO0df38_.jpg was dark, removed\n",
      "NAJILNO-upper-110_Q_r2G1vgdq.jpg was dark, removed\n",
      "MAKAVVE-front-288_mDRCuNEJXr.jpg was dark, removed\n",
      "HASATVE-front_right-right-161_gnYbMlKysP.jpg was dark, removed\n",
      "HASATVE-front_right-right-161_dxxmt-wCDO.jpg was dark, removed\n",
      "HASATVE-front_right-right-161_LaepwePUP5.jpg was dark, removed\n",
      "HASATVE-lower-161_wvryEcjoqz.jpg was dark, removed\n",
      "HASATVE-lower-161_vA68cjZSK2.jpg was dark, removed\n",
      "HASATVE-upper-161_r6l07RtPxQ.jpg was dark, removed\n",
      "HASATVE-upper-161_nZ9hJCDIVU.jpg was dark, removed\n",
      "HASATVE-upper-161_aeM61XWKbv.jpg was dark, removed\n",
      "HIKOJSI-front_right-right-105_eaY2aW5hSH.jpg was dark, removed\n",
      "TARUTTE-front_right-right-122_G-Hl6WkulW.jpg was dark, removed\n",
      "TARUTTE-front_right-right-122_uRD3EdwEBl.jpg was dark, removed\n",
      "MUNASMU-front_left-left-475_2y9eQYKo_H.jpg was dark, removed\n",
      "SAMETHI-front_left-left-453_8TNAa76i64.jpg was dark, removed\n",
      "SAMETHI-front_right-right-453_wlyAEU8vkH.jpg was dark, removed\n",
      "TEVINTU-front-455_i60QaW0ul2.jpg was dark, removed\n",
      "HEVIJSA-lower-450_7IhFXVtJdf.jpg was dark, removed\n",
      "HEVIJSA-lower-450_y-gIYPXA8Z.jpg was dark, removed\n",
      "HEVIJSA-lower-450_Yto45S3SFj.jpg was dark, removed\n",
      "NEVOPSO-lower-214_XSbhin85PG.jpg was dark, removed\n",
      "NEVOPSO-lower-214_BYOzjFqhb1.jpg was dark, removed\n",
      "NEVOPSO-upper-214_0cua_pbzSF.jpg was dark, removed\n",
      "NEVOPSO-upper-214_UnZU5Kk3cP.jpg was dark, removed\n",
      "NEVOPSO-front_left-left-214_fqP7QJHUfs.jpg was dark, removed\n",
      "NEVOPSO-front_left-left-214_2Is_SSmEuy.jpg was dark, removed\n",
      "NEVOPSO-front_left-left-214_Nlakkj2E23.jpg was dark, removed\n",
      "PAROHTA-front-437_Iaxu3Xf7pR.jpg was dark, removed\n",
      "VONERLO-front_left-left-295_tmgev5C_9n.jpg was dark, removed\n",
      "VONERLO-front_left-left-295_HI7WDtJRYG.jpg was dark, removed\n",
      "VONERLO-front_left-left-295_gUMpZc_66s.jpg was dark, removed\n",
      "VONERLO-front_left-left-295_yxK3t9iU52.jpg was dark, removed\n",
      "VONERLO-front_left-left-295_Q1law61c98.jpg was dark, removed\n",
      "VONERLO-front-295_pV3EXveEPI.jpg was dark, removed\n",
      "VONERLO-front-295_FUb2bzx93K.jpg was dark, removed\n",
      "RAVAMTO-front_left-left-284_V3-XQb7U-f.jpg was dark, removed\n",
      "RAVAMTO-front-284_cWWHxrpdhh.jpg was dark, removed\n",
      "KEVUPHI-lower-427_YBLX7gMli4.jpg was dark, removed\n",
      "KELULPO-lower-1_0bE-IurPNN.jpg was dark, removed\n",
      "VELUNJU-front_left-left-365_dM-a7aawHc.jpg was dark, removed\n",
      "MIPEJLU-front-367_55vwFlHOx7.jpg was dark, removed\n",
      "MANEPJO-front_left-left-289_ERGtHYvbP5.jpg was dark, removed\n",
      "JUVASVU-front_left-left-30_DQWkFcu3Wf.jpg was dark, removed\n",
      "SAKURPE-front_left-right-67_4GUQEcy2cH.jpg was dark, removed\n",
      "PUKOJJE-front-396_aCkpUEFfYv.jpg was dark, removed\n",
      "KEMOMMU-upper-173_ELYbTLlPQu.jpg was dark, removed\n",
      "KEMOMMU-upper-173_k-zbvrgWkM.jpg was dark, removed\n",
      "NUMOTSA-front_left-right-381_3lVrU2nqg0.jpg was dark, removed\n",
      "JOSIVRU-front-94_lxsaKY6k5V.jpg was dark, removed\n",
      "TAKASHI-upper-95_NSUEvgc89V.jpg was dark, removed\n",
      "PESOMVA-lower-62_72O48LE-K8.jpg was dark, removed\n",
      "PESOMVA-lower-62__ils2rJx9P.jpg was dark, removed\n",
      "PESOMVA-lower-62_K-NsOeosPq.jpg was dark, removed\n",
      "NURINHO-front_left-left-482_sPSbKVQERK.jpg was dark, removed\n",
      "TILAMKI-lower-422_d6KEvIZ741.jpg was dark, removed\n",
      "RUKETTI-front-22_LdtlZimZeM.jpg was dark, removed\n",
      "RUKETTI-front-22_cgKvgMO4Yk.jpg was dark, removed\n",
      "RUKETTI-front_left-right-22_aeBSH7xzq9.jpg was dark, removed\n",
      "RUKETTI-upper-22__lP6dERjlp.jpg was dark, removed\n",
      "VAKARTI-front_left-left-398__ruAo4B6pX.jpg was dark, removed\n",
      "VAKARTI-front_left-left-398_s_RP_TBnQx.jpg was dark, removed\n",
      "VAKARTI-front_left-left-398_wCwVRduVie.jpg was dark, removed\n",
      "VAKARTI-front_right-right-398_IWDPBzCv6T.jpg was dark, removed\n",
      "VAKARTI-front-398_UdVtH0ya-S.jpg was dark, removed\n",
      "SOROVSI-front_right-right-331_6Apsaor7Ug.jpg was dark, removed\n",
      "SOROVSI-front_right-right-331_zqOQJ8d8Qg.jpg was dark, removed\n",
      "SOROVSI-front_right-right-331_jOgo_gOP1U.jpg was dark, removed\n",
      "SOROVSI-front_right-right-331__y1c8UfpRw.jpg was dark, removed\n",
      "SOROVSI-front_right-right-331_h3U1l0q5Zt.jpg was dark, removed\n",
      "HORESHI-upper-416_zVEK5JFGGG.jpg was dark, removed\n",
      "HORESHI-upper-416_WaKqhwkR_x.jpg was dark, removed\n",
      "HORESHI-upper-416_I7mc8_NJg1.jpg was dark, removed\n",
      "HORESHI-lower-416_8yDueklI99.jpg was dark, removed\n",
      "KASUNSI-front_left-left-479_ZwHTdzI8xH.jpg was dark, removed\n",
      "JIPATSI-upper-454_i-fLQCjxeE.jpg was dark, removed\n",
      "JIPATSI-front_left-left-454_ILDZZDeKMc.jpg was dark, removed\n",
      "JIPATSI-front_right-right-454_p9Kujoii5_.jpg was dark, removed\n",
      "NAROPRA-front-right-309_bYO0g-db5c.jpg was dark, removed\n",
      "NAROPRA-front-309_QxY81rHsxY.jpg was dark, removed\n",
      "VISASKI-front-410_nc2h8mQd-O.jpg was dark, removed\n",
      "HEPOSHA-front_left-left-287_FNklipVKDo.jpg was dark, removed\n",
      "PUKUKSA-front_left-left-90_ffJllY89El.jpg was dark, removed\n",
      "PUKUKSA-front_right-right-90_ZF8TkhfMe2.jpg was dark, removed\n",
      "LIMORHU-front-23_KoUxrjLQQw.jpg was dark, removed\n",
      "LIMORHU-front-23_Zwy0lyBHxQ.jpg was dark, removed\n",
      "LIMORHU-upper-23_oJ0k1KtYhT.jpg was dark, removed\n",
      "PUJAJVE-front_left-left-303_NQhcEbqxHq.jpg was dark, removed\n",
      "PUJAJVE-front_left-left-303_hBY5CP-avp.jpg was dark, removed\n",
      "PUJAJVE-front_left-left-303_0P4gh3wbow.jpg was dark, removed\n",
      "PUJAJVE-front_left-left-303_MTLByQzWir.jpg was dark, removed\n",
      "PUJAJVE-lower-303_2Xw5ak5fwe.jpg was dark, removed\n",
      "PUJAJVE-lower-303_Et0IcU1dlm.jpg was dark, removed\n",
      "PUJAJVE-lower-303_H_V027WPnH.jpg was dark, removed\n",
      "PUJAJVE-lower-303_ceXNNeGbA5.jpg was dark, removed\n",
      "PUJAJVE-upper-303_zVk9rJb_46.jpg was dark, removed\n",
      "VORAMVU-upper-372_sVYqTW81B9.jpg was dark, removed\n",
      "MUNIPHU-front-474_5mjkghWxQ2.jpg was dark, removed\n",
      "HASATVE-front_left-left-161_FoiwWREuhA.jpg was dark, removed\n",
      "HASATVE-front_left-left-161_tDUplp1RE_.jpg was dark, removed\n",
      "VOTULJE-front_right-right-199_xEUfjJgN82.jpg was dark, removed\n",
      "SUKUJSU-front_left-left-305_stTdZPqbBh.jpg was dark, removed\n",
      "SUKUJSU-front_left-left-305_fIMopZWu7B.jpg was dark, removed\n",
      "SUKUJSU-front_right-right-305_AzL8ZvLuHF.jpg was dark, removed\n",
      "SUKUJSU-front_right-right-305_YKzVUal_XC.jpg was dark, removed\n",
      "LUVUMSU-front_right-right-293_s8CgG_Itam.jpg was dark, removed\n",
      "LEHEHSE-front_right-right-82_xblN8CDRGa.jpg was dark, removed\n",
      "NASAJLI-upper-44_vFdC6doQai.jpg was dark, removed\n",
      "HALUVSA-front_left-left-160_vZuu27amSU.jpg was dark, removed\n",
      "HALUVSA-front-160_lSZmzj6jOt.jpg was dark, removed\n",
      "HALUVSA-front-160_BPfWp40kEV.jpg was dark, removed\n",
      "HALUVSA-front-160_GGUlhEFmLy.jpg was dark, removed\n",
      "HALUVSA-front-160_GohZ46IDUO.jpg was dark, removed\n",
      "HALUVSA-front-160_xNZJ3yVHqo.jpg was dark, removed\n",
      "HALUVSA-front-160_QcAwbZvM-L.jpg was dark, removed\n",
      "VUNASNI-front_left-left-426_dCSSxXhyjR.jpg was dark, removed\n",
      "VUNASNI-front_left-left-426_8quM1ksdl0.jpg was dark, removed\n",
      "VUNASNI-front_left-left-426_jAJEOyImmr.jpg was dark, removed\n",
      "VUNASNI-front_left-left-426_E3eLyX7Vt9.jpg was dark, removed\n",
      "VUNASNI-front_right-right-426_IPb4tBdf-b.jpg was dark, removed\n",
      "VUNASNI-lower-426_zBwKk93IOK.jpg was dark, removed\n",
      "VUNASNI-lower-426_uEWWv-01bw.jpg was dark, removed\n",
      "VUNASNI-lower-426_B6XrQCfU6r.jpg was dark, removed\n",
      "REVETVE-front_right-right-168_TgBjNkAR03.jpg was dark, removed\n",
      "VORANHA-front_left-left-395_jEdOciexND.jpg was dark, removed\n",
      "VORANHA-front_right-right-395_ViFna17DY9.jpg was dark, removed\n",
      "VORANHA-front-395_-FNtKdtxfm.jpg was dark, removed\n",
      "VORANHA-front-395_S1PdbE8AlH.jpg was dark, removed\n",
      "LEKAPKU-front-107_2PDOgusYxi.jpg was dark, removed\n",
      "LEKAPKU-front_right-right-107_IhUMgBP3VW.jpg was dark, removed\n",
      "SONAJHO-front_left-left-444_cuFwKdN6mS.jpg was dark, removed\n",
      "SONAJHO-front_left-left-444_jS0cSpppRG.jpg was dark, removed\n",
      "TUMAVKA-front_right-right-89_eMt0s24kLa.jpg was dark, removed\n",
      "VETERVO-front_left-left-104_srYu1kPXET.jpg was dark, removed\n",
      "VETERVO-front_left-left-104_3A7ACy8NQL.jpg was dark, removed\n",
      "VETERVO-front_left-left-104_x3wz3s2XWe.jpg was dark, removed\n",
      "VETERVO-upper-104_SBymz4-9sn.jpg was dark, removed\n",
      "VETERVO-upper-104_KsIYWnxKdS.jpg was dark, removed\n",
      "VETERVO-upper-104_GcJKniCS0M.jpg was dark, removed\n",
      "VETERVO-upper-104_IENmQWb5kJ.jpg was dark, removed\n",
      "RAVOSVU-front_left-left-417_e72GczEvSI.jpg was dark, removed\n",
      "RAVOSVU-front_left-left-417_dQYuzpdnl5.jpg was dark, removed\n",
      "VEKENRA-front-146_sf8mJiVVH4.jpg was dark, removed\n",
      "MEVOMKA-front_left-left-85_T4y_dSChA3.jpg was dark, removed\n",
      "RUNAVVA-front_right-right-290_pkScgk5RLs.jpg was dark, removed\n",
      "MUTUJVE-lower-420_R8xNiJ2PPb.jpg was dark, removed\n",
      "NEPEPJI-lower-70_8onSk8PJ7w.jpg was dark, removed\n",
      "RUJIKLO-front-78_iRy5lSk2oP.jpg was dark, removed\n",
      "RUTANHO-front_right-right-348_Hupvd76ukK.jpg was dark, removed\n",
      "NATIPRI-lower-384_RyPsAQ2TLg.jpg was dark, removed\n",
      "NATIPRI-lower-384_ln1Pri6R4N.jpg was dark, removed\n",
      "KONUKHU-front_right-right-351_2BLJq7EdE7.jpg was dark, removed\n",
      "KONUKHU-front_right-right-351_HfHQsNkxz3.jpg was dark, removed\n",
      "KONUKHU-front_right-right-351_kbe_uZrUzN.jpg was dark, removed\n",
      "RELATTO-front_left-left-360_xWZcGRQvth.jpg was dark, removed\n",
      "JINUKMO-front_right-left-32_eBOA7UG3ab.jpg was dark, removed\n",
      "JINUKMO-front_right-left-32_7Nhm6gkmbB.jpg was dark, removed\n",
      "JINUKMO-front_right-left-32_kSs61WAJQR.jpg was dark, removed\n",
      "SITISVU-front_left-left-481_vMjMubLwru.jpg was dark, removed\n",
      "SENOTMU-lower-439_M5wVtYKxRy.jpg was dark, removed\n",
      "VEHEVKA-front_right-right-291_Iukf9ZeQUK.jpg was dark, removed\n",
      "JEVUTVA-front_right-right-391_thH_ETNoV2.jpg was dark, removed\n",
      "ROMEJRA-front-45_nkDuutauYe.jpg was dark, removed\n",
      "ROMEJRA-front-45_aBcxMqk9o7.jpg was dark, removed\n",
      "ROMEJRA-front_right-right-45_uskrEGeYPo.jpg was dark, removed\n",
      "ROMEJRA-upper-45_eC53S9ECm6.jpg was dark, removed\n",
      "TULULPE-front_left-left-17_teeth20240921T202280_3.jpg was dark, removed\n",
      "JEJUVHA-lower-441_P-6Xzc7B8T.jpg was dark, removed\n",
      "HAKAHNA-front-323_NMUn9_ARz4.jpg was dark, removed\n",
      "HAKAHNA-front-323_5iQiOQHdKL.jpg was dark, removed\n",
      "HAKAHNA-front-323_59Uo5PzWt0.jpg was dark, removed\n",
      "HAKAHNA-front-323_toCBPD33R5.jpg was dark, removed\n",
      "HAKAHNA-front-323_BGELGQs5en.jpg was dark, removed\n",
      "HAKAHNA-front_left-left-323_TTEu1n0kuf.jpg was dark, removed\n",
      "MOVIPKA-front_right-right-120_QeMba0AFAn.jpg was dark, removed\n",
      "MOVIPKA-front_right-right-120_oxLlpvCdOl.jpg was dark, removed\n",
      "MOVIPKA-front_right-right-120_WFfmsVyhvp.jpg was dark, removed\n",
      "TOPAHNI-front_right-right-134_smBUO1obmx.jpg was dark, removed\n",
      "SIROSVA-front_left-left-359_W5iTMprLyU.jpg was dark, removed\n",
      "SIROSVA-front_left-left-359_7p_luAgK2j.jpg was dark, removed\n",
      "Number of filtered annotations: 865\n",
      "Saving filtered annotations...\n",
      "Converting annotations...\n",
      "Number of annotations: 10017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  40%|███▉      | 4004/10017 [05:31<06:06, 16.39image/s]  c:\\Users\\anedaeij23\\Project\\tooth_classification_project\\src\\data_pipeline.py:595: UserWarning: C:/Users/anedaeij23/Project/tooth_classification_project/data/processed\\RAHIHSO-lower-48_6O7OY60DkG.jpg is a low contrast image\n",
      "  io.imsave(out_path, image)\n",
      "Processing images:  89%|████████▊ | 8873/10017 [11:46<01:03, 18.06image/s]c:\\Users\\anedaeij23\\Project\\tooth_classification_project\\src\\data_pipeline.py:595: UserWarning: C:/Users/anedaeij23/Project/tooth_classification_project/data/processed\\VEHEVKA-upper-291_jNRsr7s09J.jpg is a low contrast image\n",
      "  io.imsave(out_path, image)\n",
      "Processing images: 100%|██████████| 10017/10017 [13:43<00:00, 12.17image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done pre-processing the dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "annot_path = 'C:/Users/anedaeij23/Project/tooth_classification_project/data/raw/complete_toothwise_annotations.json'\n",
    "data_dir = 'C:/Users/anedaeij23/Project/tooth_classification_project/'\n",
    "dp.preprocess_dataset(\n",
    "    json_annotations_path= annot_path,\n",
    "    output_dir= os.path.join(data_dir,Config.OUTPUT_DIR),\n",
    "    image_dir= os.path.join(data_dir,Config.IMAGE_DIR),\n",
    "    target_dim= Config.TARGET_DIM,\n",
    "    mask_bg= Config.MASK_BG,\n",
    "    verbose= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "annot_path = 'C:/Users/anedaeij23/Project/tooth_classification_project/data/processed/filtered_Pla_annotations.json'\n",
    "data_dir = 'C:/Users/anedaeij23/Project/tooth_classification_project/'\n",
    "\n",
    "\n",
    "#loading the raw json file\n",
    "with open(annot_path, 'r', encoding='utf-8') as f:\n",
    "    annotations = json.load(f) \n",
    "dataset = dp.build_tf_dataset(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 256, 256, 3) (32,)\n"
     ]
    }
   ],
   "source": [
    "data = dataset.prefetch(1)\n",
    "for batch in data:\n",
    "    print(batch[0].shape, batch[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "annot_path = 'C:/Users/anedaeij23/Project/tooth_classification_project/data/raw/complete_toothwise_annotations.json'\n",
    "data_dir = 'C:/Users/anedaeij23/Project/tooth_classification_project/'\n",
    "\n",
    "\n",
    "#loading the raw json file\n",
    "with open(annot_path, 'r', encoding='utf-8') as f:\n",
    "    annotations = json.load(f) \n",
    "converted_annotations = dp.convert_annotations(annotations, target_class='Pla')\n",
    "\n",
    "with open(os.path.join(os.path.join(data_dir,Config.OUTPUT_DIR),f\"filtered_{Config.TARGET_CLASS}_annotations.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(converted_annotations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'teeth_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove_dark_images_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconverted_annotations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43mConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMAGE_DIR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# with open(os.path.join(os.path.join(data_dir,Config.OUTPUT_DIR),f\"filtered2_{Config.TARGET_CLASS}_annotations.json\"), \"w\", encoding=\"utf-8\") as f:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#     json.dump(filtered_annotations, f)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anedaeij23\\Project\\tooth_classification_project\\src\\data_pipeline.py:253\u001b[0m, in \u001b[0;36mremove_dark_images_from_json\u001b[1;34m(json_data, image_base_path)\u001b[0m\n\u001b[0;32m    251\u001b[0m filtered_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, entry \u001b[38;5;129;01min\u001b[39;00m json_data\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 253\u001b[0m     teeth_data \u001b[38;5;241m=\u001b[39m \u001b[43mentry\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mteeth_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    254\u001b[0m     filtered_teeth \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tooth_key, tooth_entry \u001b[38;5;129;01min\u001b[39;00m teeth_data\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mKeyError\u001b[0m: 'teeth_data'"
     ]
    }
   ],
   "source": [
    "dp.remove_dark_images_from_json(converted_annotations, os.path.join(data_dir,Config.IMAGE_DIR))\n",
    "# with open(os.path.join(os.path.join(data_dir,Config.OUTPUT_DIR),f\"filtered2_{Config.TARGET_CLASS}_annotations.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(filtered_annotations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.is_darker_than_threshold('C:/Users/anedaeij23/Project/tooth_classification_project/data/raw/HAJATRO-upper-392_EsJvScrhpS.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_conf = Config()\n",
    "test_conf.TEST_RATIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Config.TEST_RATIO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrcnn_xcnn_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
